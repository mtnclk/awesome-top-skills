# 标签：vllm (vllm)

- 返回: [标签（中文）](README.md)
- 命中技能: 8

| 技能 | 仓库 | 简介 | ⭐ | ⬇️ | 更新 | 标签 |
| - | - | - | -: | -: | - | - |
| [serving-llms-vllm](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/inference-serving-vllm/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 使用 vLLM 高效部署 LLM API，支持 OpenAI 兼容端点。 | 20K | 127 | 2026-02-16 | [API](api.md), [部署 (deployment)](deployment.md), [LLM 优化 (llm-optimization)](llm-optimization.md), [vllm (vllm)](vllm.md), [性能优化 (performance)](performance.md) |
| [evaluating-llms-harness](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/evaluation-lm-evaluation-harness/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 评估LLM在60多个学术基准上的表现，支持HuggingFace、vLLM和API。 | 20K | 118 | 2026-02-16 | [eval (eval)](eval.md), [benchmarking (benchmarking)](benchmarking.md), [LLM 优化 (llm-optimization)](llm-optimization.md), [huggingface (huggingface)](huggingface.md), [vllm (vllm)](vllm.md) |
| [outlines](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/prompt-engineering-outlines/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 确保生成时的 JSON/XML/代码结构有效，支持本地模型快速推理。 | 20K | 118 | 2026-02-16 | [编码 (coding)](coding.md), [工具链 (tooling)](tooling.md), [pydantic (pydantic)](pydantic.md), [vllm (vllm)](vllm.md), [transformers (transformers)](transformers.md) |
| [speculative-decoding](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/emerging-techniques-speculative-decoding/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 使用推测解码等技术优化LLM推理速度。 | 20K | 113 | 2026-02-16 | [LLM 优化 (llm-optimization)](llm-optimization.md), [性能优化 (performance)](performance.md), [部署 (deployment)](deployment.md), [LLM](llm.md), [vllm (vllm)](vllm.md), [medusa (medusa)](medusa.md) |
| [sglang](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/inference-serving-sglang/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 基于RadixAttention前缀缓存的快速结构化LLM生成与服务。 | 20K | 105 | 2026-02-16 | [LLM 优化 (llm-optimization)](llm-optimization.md), [text generation (text-generation)](text-generation.md), [工具链 (tooling)](tooling.md), [vllm (vllm)](vllm.md), [gpu (gpu)](gpu.md) |
| [openrlhf-training](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/post-training-openrlhf/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 基于 Ray 和 vLLM 的高性能 RLHF 框架，用于大模型训练。 | 20K | 100 | 2026-02-16 | [training (training)](training.md), [LLM 优化 (llm-optimization)](llm-optimization.md), [机器学习 (machine-learning)](machine-learning.md), [ray (ray)](ray.md), [vllm (vllm)](vllm.md) |
| [hqq-quantization](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/optimization-hqq/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 无需校准数据即可将LLM量化至4/3/2位精度，适用于vLLM或HuggingFace的快速部署。 | 20K | 94 | 2026-02-16 | [LLM 优化 (llm-optimization)](llm-optimization.md), [vllm (vllm)](vllm.md), [huggingface transformers (huggingface-transformers)](huggingface-transformers.md) |
| [llamaguard](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/safety-alignment-llamaguard/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Meta的7-8B专用LLM内容审核模型，支持6种安全类别过滤。 | 20K | 94 | 2026-02-16 | [guardrails (guardrails)](guardrails.md), [moderation (moderation)](moderation.md), [LLM](llm.md), [huggingface (huggingface)](huggingface.md), [vllm (vllm)](vllm.md) |
