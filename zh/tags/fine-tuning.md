# 标签：fine tuning (fine-tuning)

- 返回: [标签（中文）](README.md)
- 命中技能: 14

| 技能 | 仓库 | 简介 | ⭐ | ⬇️ | 更新 | 标签 |
| - | - | - | -: | -: | - | - |
| [fine-tuning-expert](https://github.com/jeffallan/claude-skills/blob/main/skills/fine-tuning-expert/SKILL.md) | [jeffallan/claude-skills](https://github.com/jeffallan/claude-skills) | 通过微调、高效参数方法和数据集准备优化LLM性能。 | 2.9K | 211 | 2026-02-13 | [LLM 优化 (llm-optimization)](llm-optimization.md), [机器学习 (machine-learning)](machine-learning.md), [fine tuning (fine-tuning)](fine-tuning.md) |
| [model-merging](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/emerging-techniques-model-merging/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 使用mergekit合并多个微调模型以提升性能和实验。 | 21K | 131 | 2026-02-17 | [LLM 优化 (llm-optimization)](llm-optimization.md), [modeling (modeling)](modeling.md), [fine tuning (fine-tuning)](fine-tuning.md), [机器学习 (machine-learning)](machine-learning.md), [部署 (deployment)](deployment.md) |
| [peft-fine-tuning](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/fine-tuning-peft/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 使用LoRA、QLoRA等方法进行高效LLM微调，适用于显存受限场景。 | 21K | 123 | 2026-02-17 | [fine tuning (fine-tuning)](fine-tuning.md), [LLM 优化 (llm-optimization)](llm-optimization.md), [huggingface (huggingface)](huggingface.md), [transformers (transformers)](transformers.md), [gpu (gpu)](gpu.md) |
| [unsloth](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/fine-tuning-unsloth/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 使用 Unsloth 快速微调 LLM，训练速度提升 2-5 倍，内存占用减少 50-80%。 | 21K | 116 | 2026-02-17 | [fine tuning (fine-tuning)](fine-tuning.md), [LLM 优化 (llm-optimization)](llm-optimization.md), [性能优化 (performance)](performance.md), [pytorch (pytorch)](pytorch.md), [transformers (transformers)](transformers.md) |
| [llama-factory](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/fine-tuning-llama-factory/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 使用LLaMA-Factory微调LLM的技能，支持WebUI和QLoRA。 | 21K | 115 | 2026-02-17 | [fine tuning (fine-tuning)](fine-tuning.md), [LLM 优化 (llm-optimization)](llm-optimization.md), [multimodal (multimodal)](multimodal.md), [huggingface (huggingface)](huggingface.md), [LLM](llm.md) |
| [fine-tuning-with-trl](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/post-training-trl-fine-tuning/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 使用TRL进行强化学习微调LLM，支持SFT、DPO、PPO和奖励建模。 | 21K | 112 | 2026-02-17 | [LLM 优化 (llm-optimization)](llm-optimization.md), [fine tuning (fine-tuning)](fine-tuning.md), [reinforcement learning (reinforcement-learning)](reinforcement-learning.md), [huggingface (huggingface)](huggingface.md), [transformers (transformers)](transformers.md) |
| [implementing-llms-litgpt](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/model-architecture-litgpt/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 使用LitGPT实现和训练20+架构的LLM，如Llama、Gemma、Phi等。 | 21K | 106 | 2026-02-17 | [编码 (coding)](coding.md), [LLM 优化 (llm-optimization)](llm-optimization.md), [fine tuning (fine-tuning)](fine-tuning.md), [LLM](llm.md), [pytorch (pytorch)](pytorch.md) |
| [axolotl](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/fine-tuning-axolotl/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 使用Axolotl微调LLM的专家指导，支持YAML配置、LoRA/QLoRA、DPO/KTO/ORPO/GRPO及多模 | 21K | 102 | 2026-02-17 | [fine tuning (fine-tuning)](fine-tuning.md), [LLM 优化 (llm-optimization)](llm-optimization.md), [multimodal (multimodal)](multimodal.md), [yaml (yaml)](yaml.md), [lora (lora)](lora.md) |
| [gptq](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/optimization-gptq/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 用于大型语言模型的后训练4位量化，实现最小精度损失。 | 21K | 101 | 2026-02-17 | [LLM 优化 (llm-optimization)](llm-optimization.md), [部署 (deployment)](deployment.md), [fine tuning (fine-tuning)](fine-tuning.md), [transformers (transformers)](transformers.md), [peft (peft)](peft.md) |
| [grpo-rl-training](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/post-training-grpo-rl-training/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | GRPO/RL微调专家指导，使用TRL进行推理和特定任务建模。 | 21K | 101 | 2026-02-17 | [fine tuning (fine-tuning)](fine-tuning.md), [reinforcement learning (reinforcement-learning)](reinforcement-learning.md), [LLM 优化 (llm-optimization)](llm-optimization.md), [trl (trl)](trl.md), [grpo (grpo)](grpo.md) |
| [simpo-training](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/post-training-simpo/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 一种无需参考模型的简单高效LLM偏好对齐方法。 | 21K | 97 | 2026-02-17 | [LLM 优化 (llm-optimization)](llm-optimization.md), [training (training)](training.md), [fine tuning (fine-tuning)](fine-tuning.md) |
| [hugging-face-model-trainer](https://github.com/huggingface/skills/blob/main/skills/hugging-face-model-trainer/SKILL.md) | [huggingface/skills](https://github.com/huggingface/skills) | 使用Hugging Face Jobs基础设施训练或微调语言模型。 | 1.2K | 87 | 2026-02-06 | [机器学习 (machine-learning)](machine-learning.md), [fine tuning (fine-tuning)](fine-tuning.md), [huggingface (huggingface)](huggingface.md), [trl (trl)](trl.md), [gguf (gguf)](gguf.md), [gpu (gpu)](gpu.md) |
| [fine-tuning-assistant](https://github.com/eddiebe147/claude-settings) | [eddiebe147/claude-settings](https://github.com/eddiebe147/claude-settings) | 指导语言模型微调以实现定制化AI性能。 | 15 | 45 | 2026-01-22 | [LLM 优化 (llm-optimization)](llm-optimization.md), [fine tuning (fine-tuning)](fine-tuning.md), [机器学习 (machine-learning)](machine-learning.md), [model 监控 (model-monitoring)](model-monitoring.md) |
| [ai-llm](https://github.com/vasilyu1983/ai-agents-public/blob/main/frameworks/shared-skills/skills/ai-llm/SKILL.md) | [vasilyu1983/ai-agents-public](https://github.com/vasilyu1983/ai-agents-public) | 生产级LLM工程技能，涵盖策略选择、数据集设计、PEFT/LoRA、评估工作流和部署。 | 31 | 23 | 2026-01-26 | [LLM 优化 (llm-optimization)](llm-optimization.md), [prompting (prompting)](prompting.md), [RAG（检索增强生成） (rag)](rag.md), [fine tuning (fine-tuning)](fine-tuning.md), [evaluation (evaluation)](evaluation.md), [部署 (deployment)](deployment.md) |
