# 标签：training (training)

- 返回: [标签（中文）](README.md)
- 命中技能: 5

| 技能 | 仓库 | 简介 | ⭐ | ⬇️ | 更新 | 标签 |
| - | - | - | -: | -: | - | - |
| [training-llms-megatron](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/distributed-training-megatron-core/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 使用NVIDIA Megatron-Core训练大规模语言模型，实现高GPU效率和高级并行策略。 | 21K | 125 | 2026-02-17 | [LLM 优化 (llm-optimization)](llm-optimization.md), [机器学习 (machine-learning)](machine-learning.md), [training (training)](training.md), [gpu (gpu)](gpu.md), [megatron (megatron)](megatron.md) |
| [openrlhf-training](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/post-training-openrlhf/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 基于 Ray 和 vLLM 的高性能 RLHF 框架，用于大模型训练。 | 21K | 102 | 2026-02-17 | [training (training)](training.md), [LLM 优化 (llm-optimization)](llm-optimization.md), [机器学习 (machine-learning)](machine-learning.md), [ray (ray)](ray.md), [vllm (vllm)](vllm.md) |
| [simpo-training](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/post-training-simpo/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 一种无需参考模型的简单高效LLM偏好对齐方法。 | 21K | 97 | 2026-02-17 | [LLM 优化 (llm-optimization)](llm-optimization.md), [training (training)](training.md), [fine tuning (fine-tuning)](fine-tuning.md) |
| [competency-builder](https://github.com/jwynia/agent-skills/blob/main/skills/general/education/competency/SKILL.md) | [jwynia/agent-skills](https://github.com/jwynia/agent-skills) | 指导能力框架开发与运营，用于培训能力建设。 | 22 | 37 | 2026-02-15 | [规划 (planning)](planning.md), [最佳实践 (best-practices)](best-practices.md), [training (training)](training.md) |
| [distributed-llm-pretraining-torchtitan](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/model-architecture-torchtitan/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | 基于 PyTorch 的分布式 LLM 预训练工具，支持 4D 并行，可扩展至 512+ GPU。 | 21K | 21 | 2026-02-17 | [机器学习 (machine-learning)](machine-learning.md), [training (training)](training.md), [pytorch (pytorch)](pytorch.md), [LLM](llm.md), [distributed systems (distributed-systems)](distributed-systems.md) |
