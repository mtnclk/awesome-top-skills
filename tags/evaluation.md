# Tag: evaluation

- Back: [Tags](README.md)
- Tagged skills: 11

| Skill | Repo | Summary | ⭐ | ⬇️ | Updated | Tags |
| - | - | - | -: | -: | - | - |
| [prompt-engineer](https://github.com/jeffallan/claude-skills/blob/main/skills/prompt-engineer/SKILL.md) | [jeffallan/claude-skills](https://github.com/jeffallan/claude-skills) | Optimize LLM prompts, enhance model performance, and implement advanced prompting techniques. | 2.5K | 234 | 2026-02-13 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [evaluation](evaluation.md), [llm](llm.md) |
| [decision-helper](https://github.com/shubhamsaboo/awesome-llm-apps/blob/main/awesome_agent_skills/decision-helper/SKILL.md) | [shubhamsaboo/awesome-llm-apps](https://github.com/shubhamsaboo/awesome-llm-apps) | Structured decision-making frameworks for evaluating options and making informed choices. | 95K | 201 | 2026-02-12 | [decision-making](decision-making.md), [analysis](analysis.md), [planning](planning.md), [evaluation](evaluation.md), [strategy](strategy.md) |
| [senior-prompt-engineer](https://github.com/alirezarezvani/claude-skills/blob/main/engineering-team/senior-prompt-engineer/SKILL.md) | [alirezarezvani/claude-skills](https://github.com/alirezarezvani/claude-skills) | A skill for optimizing prompts, designing prompt templates, evaluating LLM outputs, and building agentic systems. | 1.8K | 130 | 2026-02-10 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [evaluation](evaluation.md), [rag](rag.md), [agents](agents.md), [workflows](workflows.md) |
| [peer-review](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/scientific/peer-review/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A systematic peer review toolkit for evaluating research manuscripts and grants across disciplines. | 20K | 123 | 2026-02-15 | [audit](audit.md), [evaluation](evaluation.md), [literature-review](literature-review.md), [academic-papers](academic-papers.md) |
| [peer-review](https://github.com/k-dense-ai/claude-scientific-skills/blob/main/scientific-skills/peer-review/SKILL.md) | [k-dense-ai/claude-scientific-skills](https://github.com/k-dense-ai/claude-scientific-skills) | A structured peer review skill for manuscripts and grants with checklist-based evaluation. | 7.8K | 88 | 2026-02-04 | [literature-review](literature-review.md), [evaluation](evaluation.md), [academic-papers](academic-papers.md) |
| [evaluating-candidates](https://github.com/refoundai/lenny-skills/blob/main/skills/evaluating-candidates/SKILL.md) | [refoundai/lenny-skills](https://github.com/refoundai/lenny-skills) | Helps users make better hiring decisions by evaluating candidates, conducting reference checks, and reviewing work samples. | 231 | 69 | 2026-01-31 | [evaluation](evaluation.md), [hiring](hiring.md), [decision-making](decision-making.md), [task-management](task-management.md), [planning](planning.md) |
| [content-quality-auditor](https://github.com/aaron-he-zhu/seo-geo-claude-skills/blob/main/cross-cutting/content-quality-auditor/SKILL.md) | [aaron-he-zhu/seo-geo-claude-skills](https://github.com/aaron-he-zhu/seo-geo-claude-skills) | Performs comprehensive CORE-EEAT content quality audits with 80-item scoring across 8 dimensions, producing detailed reports and action plan | 184 | 42 | 2026-02-14 | [audit](audit.md), [assessment](assessment.md), [seo](seo.md), [content-strategy](content-strategy.md), [evaluation](evaluation.md) |
| [review-docs](https://github.com/tldraw/tldraw/blob/main/.claude/skills/review-docs/SKILL.md) | [tldraw/tldraw](https://github.com/tldraw/tldraw) | Review and improve documentation with parallel evaluation and iterative improvement loop. | 45K | 30 | 2026-02-15 | [documentation](documentation.md), [review](review.md), [quality-management](quality-management.md), [iterative-improvement](iterative-improvement.md), [evaluation](evaluation.md) |
| [meta-cognitive-reasoning](https://github.com/89jobrien/steve/blob/main/steve/skills/meta-cognitive-reasoning/SKILL.md) | [89jobrien/steve](https://github.com/89jobrien/steve) | Meta-cognitive reasoning specialist for evidence-based analysis, hypothesis testing, and cognitive failure prevention in complex analytical | 1 | 24 | 2026-01-06 | [analysis](analysis.md), [hypothesis-testing](hypothesis-testing.md), [reasoning](reasoning.md), [cognitive-psychology](cognitive-psychology.md), [evaluation](evaluation.md) |
| [ai-llm](https://github.com/vasilyu1983/ai-agents-public/blob/main/frameworks/shared-skills/skills/ai-llm/SKILL.md) | [vasilyu1983/ai-agents-public](https://github.com/vasilyu1983/ai-agents-public) | A production LLM engineering skill covering strategy selection, dataset design, PEFT/LoRA, evaluation workflows, and deployment. | 30 | 23 | 2026-01-26 | [llm-optimization](llm-optimization.md), [prompting](prompting.md), [rag](rag.md), [fine-tuning](fine-tuning.md), [evaluation](evaluation.md), [deployment](deployment.md) |
| [evaluation](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/evaluation/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Build evaluation frameworks for agent systems | 8.9K | 22 | 2026-02-14 | [evaluation](evaluation.md), [testing](testing.md), [agents](agents.md), [framework](framework.md) |
