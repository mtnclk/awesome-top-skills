# Tag: llm-optimization

- Back: [Tags](README.md)
- Tagged skills: 167

| Skill | Repo | Summary | ⭐ | ⬇️ | Updated | Tags |
| - | - | - | -: | -: | - | - |
| [codex](https://github.com/softaworks/agent-toolkit/blob/main/skills/codex/SKILL.md) | [softaworks/agent-toolkit](https://github.com/softaworks/agent-toolkit) | A skill for using Codex CLI with GPT-5.2 for code analysis, refactoring, and automated editing. | 433 | 2.9K | 2026-02-02 | [coding](coding.md), [cli](cli.md), [codex](codex.md), [llm-optimization](llm-optimization.md) |
| [humanizer](https://github.com/softaworks/agent-toolkit/blob/main/skills/humanizer/SKILL.md) | [softaworks/agent-toolkit](https://github.com/softaworks/agent-toolkit) | Remove AI-generated writing signs from text to make it sound more natural. | 433 | 2.8K | 2026-02-02 | [writing](writing.md), [text-generation](text-generation.md), [humanizer](humanizer.md), [llm-optimization](llm-optimization.md) |
| [prompt-engineering-patterns](https://github.com/wshobson/agents/blob/main/plugins/llm-application-dev/skills/prompt-engineering-patterns/SKILL.md) | [wshobson/agents](https://github.com/wshobson/agents) | Master advanced prompt engineering techniques for maximizing LLM performance, reliability, and controllability in production. | 28K | 1.5K | 2026-02-02 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [best-practices](best-practices.md), [llm](llm.md) |
| [firecrawl](https://github.com/firecrawl/cli/blob/main/skills/firecrawl-cli/SKILL.md) | [firecrawl/cli](https://github.com/firecrawl/cli) | Firecrawl is a web scraping and research tool optimized for LLMs, handling web operations with high accuracy and speed. | 80 | 1.3K | 2026-02-04 | [web-research](web-research.md), [scraping](scraping.md), [llm-optimization](llm-optimization.md), [internet](internet.md), [markdown](markdown.md) |
| [rag-implementation](https://github.com/wshobson/agents/blob/main/plugins/llm-application-dev/skills/rag-implementation/SKILL.md) | [wshobson/agents](https://github.com/wshobson/agents) | Implement Retrieval-Augmented Generation (RAG) systems with vector databases and semantic search for LLM applications. | 28K | 1.1K | 2026-02-02 | [rag](rag.md), [knowledge-base](knowledge-base.md), [vector-database](vector-database.md), [semantic-search](semantic-search.md), [llm-optimization](llm-optimization.md) |
| [embedding-strategies](https://github.com/wshobson/agents/blob/main/plugins/llm-application-dev/skills/embedding-strategies/SKILL.md) | [wshobson/agents](https://github.com/wshobson/agents) | Optimize embedding models for semantic search and RAG applications. | 28K | 829 | 2026-02-02 | [rag](rag.md), [embedding](embedding.md), [llm-optimization](llm-optimization.md), [vector-database](vector-database.md), [semantic-search](semantic-search.md) |
| [vector-index-tuning](https://github.com/wshobson/agents/blob/main/plugins/llm-application-dev/skills/vector-index-tuning/SKILL.md) | [wshobson/agents](https://github.com/wshobson/agents) | Optimize vector index performance for latency, recall, and memory by tuning HNSW parameters and quantization strategies. | 28K | 811 | 2026-02-02 | [llm-optimization](llm-optimization.md), [query-optimization](query-optimization.md), [vector-database](vector-database.md), [vector-search](vector-search.md), [performance](performance.md) |
| [enhance-prompt](https://github.com/google-labs-code/stitch-skills/blob/main/skills/enhance-prompt/SKILL.md) | [google-labs-code/stitch-skills](https://github.com/google-labs-code/stitch-skills) | Enhances vague UI ideas into precise, Stitch-optimized prompts with UI/UX keywords and design context. | 1.1K | 634 | 2026-02-03 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [stitch](stitch.md) |
| [humanizer](https://github.com/daleseo/korean-skills/blob/main/skills/humanizer/SKILL.md) | [daleseo/korean-skills](https://github.com/daleseo/korean-skills) | Converts AI-generated Korean text into natural human-like writing by detecting and removing 24 specific AI patterns. | 4 | 341 | 2026-02-01 | [text-generation](text-generation.md), [writing](writing.md), [llm-optimization](llm-optimization.md), [humanizer](humanizer.md) |
| [geo-fundamentals](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/geo-fundamentals/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Optimizes AI search engines like ChatGPT, Claude, and Perplexity with generative engine techniques. | 6.9K | 313 | 2026-02-03 | [llm-optimization](llm-optimization.md), [text-generation](text-generation.md), [chatgpt](chatgpt.md), [claude](claude.md), [perplexity](perplexity.md) |
| [prompt-engineer](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/prompt-engineer/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Expert prompt engineer for advanced prompting techniques, LLM optimization, and AI system design. | 6.9K | 299 | 2026-02-03 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [best-practices](best-practices.md), [ai](ai.md), [llm](llm.md) |
| [claude-automation-recommender](https://github.com/anthropics/claude-plugins-official/blob/main/plugins/claude-code-setup/skills/claude-automation-recommender/SKILL.md) | [anthropics/claude-plugins-official](https://github.com/anthropics/claude-plugins-official) | Recommends Claude Code automations (hooks, subagents, skills, plugins, MCP servers) by analyzing codebases. | 6.4K | 294 | 2026-01-30 | [automation](automation.md), [analysis](analysis.md), [claude](claude.md), [llm-optimization](llm-optimization.md) |
| [prompt-engineering](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/prompt-engineering/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Expert guide on prompt engineering patterns, best practices, and optimization techniques for LLMs. | 6.9K | 284 | 2026-02-03 | [prompting](prompting.md), [best-practices](best-practices.md), [llm-optimization](llm-optimization.md) |
| [continuous-learning](https://github.com/affaan-m/everything-claude-code/blob/main/skills/continuous-learning/SKILL.md) | [affaan-m/everything-claude-code](https://github.com/affaan-m/everything-claude-code) | Automatically extract reusable patterns from Claude Code sessions and save them as learned skills for future use. | 39K | 237 | 2026-02-03 | [continuous-learning](continuous-learning.md), [llm-optimization](llm-optimization.md), [agents](agents.md) |
| [ai-product](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/ai-product/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | An AI-powered product skill covering LLM integration, RAG, prompt engineering, and cost optimization. | 6.9K | 231 | 2026-02-03 | [llm-optimization](llm-optimization.md), [rag](rag.md), [prompting](prompting.md), [ai](ai.md), [architecture](architecture.md) |
| [openai-api](https://github.com/jezweb/claude-skills/blob/main/skills/openai-api/SKILL.md) | [jezweb/claude-skills](https://github.com/jezweb/claude-skills) | A skill for building applications using OpenAI's stateless APIs including Chat Completions, Embeddings, and Whisper. | 258 | 230 | 2026-02-04 | [api](api.md), [text-generation](text-generation.md), [openai](openai.md), [llm-optimization](llm-optimization.md), [error-handling](error-handling.md), [tooling](tooling.md) |
| [continuous-learning-v2](https://github.com/affaan-m/everything-claude-code/blob/main/skills/continuous-learning-v2/SKILL.md) | [affaan-m/everything-claude-code](https://github.com/affaan-m/everything-claude-code) | An instinct-based continuous learning system that evolves instincts into skills and commands. | 39K | 228 | 2026-02-03 | [continuous-learning](continuous-learning.md), [llm-optimization](llm-optimization.md), [context-management](context-management.md) |
| [context-window-management](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/context-window-management/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Manage LLM context windows with strategies like summarization, trimming, and routing to avoid context rot. | 6.9K | 223 | 2026-02-03 | [context-management](context-management.md), [llm-optimization](llm-optimization.md), [summarization](summarization.md), [token-budget](token-budget.md) |
| [senior-prompt-engineer](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/development/senior-prompt-engineer/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Expert-level prompt engineering skill for LLM optimization, structured outputs, and AI product development. | 19K | 216 | 2026-02-04 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [architecture](architecture.md), [claude](claude.md), [gpt-4](gpt-4.md) |
| [rag-engineer](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/rag-engineer/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Build Retrieval-Augmented Generation systems with expertise in embeddings, vector databases, and retrieval optimization. | 6.9K | 213 | 2026-02-03 | [rag](rag.md), [llm-optimization](llm-optimization.md), [embedding](embedding.md), [vector-database](vector-database.md), [semantic-search](semantic-search.md) |
| [autonomous-agents](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/autonomous-agents/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | An autonomous agent skill focusing on goal decomposition, planning, tool execution, and reliability in LLM systems. | 6.9K | 205 | 2026-02-03 | [agents](agents.md), [llm-optimization](llm-optimization.md), [best-practices](best-practices.md), [error-handling](error-handling.md) |
| [langgraph-docs](https://github.com/langchain-ai/deepagents/blob/master/libs/cli/examples/skills/langgraph-docs/SKILL.md) | [langchain-ai/deepagents](https://github.com/langchain-ai/deepagents) | This skill fetches LangGraph documentation for accurate and up-to-date guidance. | 8.9K | 203 | 2026-02-04 | [documentation](documentation.md), [llm-optimization](llm-optimization.md), [langchain](langchain.md), [langsmith](langsmith.md) |
| [prompt-caching](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/prompt-caching/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Optimize LLM prompt caching with Anthropic, response caching, and CAG strategies. | 6.9K | 195 | 2026-02-03 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [cache](cache.md), [anthropic](anthropic.md), [cag](cag.md) |
| [cloudflare-workers-ai](https://github.com/jezweb/claude-skills/blob/main/skills/cloudflare-workers-ai/SKILL.md) | [jezweb/claude-skills](https://github.com/jezweb/claude-skills) | Run LLMs and AI models on Cloudflare's GPU network with Workers AI, supporting multiple models and features. | 258 | 195 | 2026-02-04 | [text-generation](text-generation.md), [llm-optimization](llm-optimization.md), [cloudflare](cloudflare.md), [ai](ai.md) |
| [skill-creator](https://github.com/jezweb/claude-skills/blob/main/skills/skill-creator/SKILL.md) | [jezweb/claude-skills](https://github.com/jezweb/claude-skills) | Create effective Claude Code skills with optimized descriptions and error prevention. | 258 | 193 | 2026-02-04 | [skill-creation](skill-creation.md), [best-practices](best-practices.md), [llm-optimization](llm-optimization.md), [claude](claude.md) |
| [voice-agents](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/voice-agents/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | A skill for building voice agents with low-latency speech-to-speech or pipeline architectures. | 6.9K | 185 | 2026-02-03 | [agents](agents.md), [audio-generation](audio-generation.md), [text-to-speech](text-to-speech.md), [speech](speech.md), [realtime](realtime.md), [llm-optimization](llm-optimization.md) |
| [behavioral-modes](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/behavioral-modes/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Adapts AI behavior based on task type using predefined operational modes. | 6.9K | 181 | 2026-02-03 | [behavioral-science](behavioral-science.md), [llm-optimization](llm-optimization.md), [agents](agents.md) |
| [rag-implementation](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/rag-implementation/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Implement Retrieval-Augmented Generation (RAG) systems with vector databases and semantic search for LLM applications. | 6.9K | 179 | 2026-02-03 | [rag](rag.md), [knowledge-base](knowledge-base.md), [vector-database](vector-database.md), [semantic-search](semantic-search.md), [llm-optimization](llm-optimization.md) |
| [cc-skill-continuous-learning](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/cc-skill-continuous-learning/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | A skill for continuous learning and LLM optimization. | 6.9K | 171 | 2026-02-03 | [continuous-learning](continuous-learning.md), [llm-optimization](llm-optimization.md), [tooling](tooling.md) |
| [ralph-wiggum](https://github.com/fstandhartinger/ralph-wiggum/blob/main/skills/ralph-wiggum/SKILL.md) | [fstandhartinger/ralph-wiggum](https://github.com/fstandhartinger/ralph-wiggum) | An autonomous AI coding skill using spec-driven development with iterative bash loop methodology. | 147 | 163 | 2026-01-28 | [coding](coding.md), [automation](automation.md), [llm-optimization](llm-optimization.md), [specstory](specstory.md) |
| [prompt-engineering](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/prompt-engineering/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Expert guide on prompt engineering patterns, best practices, and optimization techniques for LLMs. | 19K | 131 | 2026-02-04 | [prompting](prompting.md), [best-practices](best-practices.md), [llm-optimization](llm-optimization.md) |
| [prompt-engineer](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/prompt-engineer/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Expert in designing effective prompts for LLM-powered applications, mastering prompt structure, context management, and output formatting. | 19K | 130 | 2026-02-04 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [context-management](context-management.md), [llm](llm.md) |
| [long-context](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/emerging-techniques-long-context/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Extend transformer model context windows using RoPE, YaRN, ALiBi, and position interpolation techniques for long document processing. | 19K | 129 | 2026-02-04 | [llm-optimization](llm-optimization.md), [context-management](context-management.md), [transformers](transformers.md), [position-interpolation](position-interpolation.md) |
| [knowledge-distillation](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/emerging-techniques-knowledge-distillation/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Compress large language models using knowledge distillation techniques for efficient deployment and reduced inference costs. | 19K | 119 | 2026-02-04 | [llm-optimization](llm-optimization.md), [machine-learning](machine-learning.md), [ai](ai.md), [transformers](transformers.md) |
| [llama-cpp](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/inference-serving-llama-cpp/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Run LLM inference on CPU, Apple Silicon, and consumer GPUs with GGUF quantization support. | 19K | 114 | 2026-02-04 | [llm-optimization](llm-optimization.md), [deployment](deployment.md), [cpu](cpu.md), [gpu](gpu.md) |
| [model-merging](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/emerging-techniques-model-merging/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Merge multiple fine-tuned models using mergekit for enhanced performance and experimentation. | 19K | 113 | 2026-02-04 | [llm-optimization](llm-optimization.md), [modeling](modeling.md), [fine-tuning](fine-tuning.md), [machine-learning](machine-learning.md), [deployment](deployment.md) |
| [deepspeed](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/distributed-training-deepspeed/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Expert guidance for distributed training with DeepSpeed including ZeRO optimization and FP16/BF16 support. | 19K | 108 | 2026-02-04 | [machine-learning](machine-learning.md), [llm-optimization](llm-optimization.md), [deepspeed](deepspeed.md), [distributed-systems](distributed-systems.md) |
| [model-pruning](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/emerging-techniques-model-pruning/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Prune large language models to reduce size and improve inference speed using techniques like Wanda and SparseGPT. | 19K | 108 | 2026-02-04 | [llm-optimization](llm-optimization.md), [machine-learning](machine-learning.md), [transformers](transformers.md), [pytorch](pytorch.md) |
| [serving-llms-vllm](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/inference-serving-vllm/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Deploy LLM APIs with high throughput using vLLM's optimizations and support for OpenAI-compatible endpoints. | 19K | 108 | 2026-02-04 | [api](api.md), [deployment](deployment.md), [llm-optimization](llm-optimization.md), [vllm](vllm.md), [performance](performance.md) |
| [training-llms-megatron](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/distributed-training-megatron-core/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Train large language models with NVIDIA Megatron-Core for high GPU efficiency and advanced parallelism. | 19K | 105 | 2026-02-04 | [llm-optimization](llm-optimization.md), [machine-learning](machine-learning.md), [training](training.md), [gpu](gpu.md), [megatron](megatron.md) |
| [dspy](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/prompt-engineering-dspy/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A framework for systematic LM programming, enabling declarative AI system building with automatic prompt optimization and modular RAG system | 19K | 103 | 2026-02-04 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [rag](rag.md), [agents](agents.md), [tooling](tooling.md), [declarative](declarative.md) |
| [huggingface-tokenizers](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/tokenization-huggingface-tokenizers/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | High-performance tokenizer for NLP tasks, supporting BPE, WordPiece, and Unigram algorithms. | 19K | 103 | 2026-02-04 | [tokenization](tokenization.md), [llm-optimization](llm-optimization.md), [huggingface](huggingface.md), [rust](rust.md), [transformers](transformers.md) |
| [llama-factory](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/fine-tuning-llama-factory/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A skill for fine-tuning LLMs using LLaMA-Factory with WebUI, supporting 100+ models and QLoRA. | 19K | 103 | 2026-02-04 | [fine-tuning](fine-tuning.md), [llm-optimization](llm-optimization.md), [multimodal](multimodal.md), [huggingface](huggingface.md), [llm](llm.md) |
| [peft-fine-tuning](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/fine-tuning-peft/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Efficient LLM fine-tuning with LoRA, QLoRA, and 25+ methods for limited GPU memory scenarios. | 19K | 103 | 2026-02-04 | [fine-tuning](fine-tuning.md), [llm-optimization](llm-optimization.md), [huggingface](huggingface.md), [transformers](transformers.md), [gpu](gpu.md) |
| [prompt-engineer](https://github.com/jeffallan/claude-skills/blob/main/skills/prompt-engineer/SKILL.md) | [jeffallan/claude-skills](https://github.com/jeffallan/claude-skills) | Optimize LLM prompts, enhance model performance, and implement advanced prompting techniques. | 244 | 103 | 2026-02-04 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [evaluation](evaluation.md), [llm](llm.md) |
| [fine-tuning-expert](https://github.com/jeffallan/claude-skills/blob/main/skills/fine-tuning-expert/SKILL.md) | [jeffallan/claude-skills](https://github.com/jeffallan/claude-skills) | Optimize LLM performance through fine-tuning, parameter-efficient methods, and dataset preparation. | 244 | 102 | 2026-02-04 | [llm-optimization](llm-optimization.md), [machine-learning](machine-learning.md), [fine-tuning](fine-tuning.md) |
| [context-window-management](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/context-window-management/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Manage LLM context windows with strategies like summarization, trimming, and routing to avoid context rot. | 19K | 101 | 2026-02-04 | [context-management](context-management.md), [llm-optimization](llm-optimization.md), [summarization](summarization.md), [token-budget](token-budget.md) |
| [tensorrt-llm](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/inference-serving-tensorrt-llm/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Optimizes LLM inference using NVIDIA TensorRT for high throughput and low latency on A100/H100 GPUs. | 19K | 101 | 2026-02-04 | [llm-optimization](llm-optimization.md), [performance](performance.md), [deployment](deployment.md), [nvidia](nvidia.md), [gpu](gpu.md) |
| [unsloth](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/fine-tuning-unsloth/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Fast fine-tuning with Unsloth for LLMs, 2-5x faster training and 50-80% less memory usage. | 19K | 101 | 2026-02-04 | [fine-tuning](fine-tuning.md), [llm-optimization](llm-optimization.md), [performance](performance.md), [pytorch](pytorch.md), [transformers](transformers.md) |
| [autonomous-agents](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/autonomous-agents/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | An autonomous agent skill focusing on goal decomposition, planning, tool execution, and reliability in LLM systems. | 19K | 100 | 2026-02-04 | [agents](agents.md), [llm-optimization](llm-optimization.md), [best-practices](best-practices.md), [error-handling](error-handling.md) |
| [evaluating-llms-harness](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/evaluation-lm-evaluation-harness/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Evaluates LLMs on 60+ academic benchmarks like MMLU, HumanEval, GSM8K, TruthfulQA, HellaSwag. Supports HuggingFace, vLLM, and APIs. | 19K | 100 | 2026-02-04 | [eval](eval.md), [benchmarking](benchmarking.md), [llm-optimization](llm-optimization.md), [huggingface](huggingface.md), [vllm](vllm.md) |
| [context-engineering](https://github.com/mrgoonie/claudekit-skills/blob/main/.claude/skills/context-engineering/SKILL.md) | [mrgoonie/claudekit-skills](https://github.com/mrgoonie/claudekit-skills) | Master context engineering for AI agents: architecture design, token optimization, memory systems, and multi-agent coordination. | 1.6K | 100 | 2026-02-03 | [context-management](context-management.md), [llm-optimization](llm-optimization.md), [agents](agents.md), [architecture](architecture.md) |
| [speculative-decoding](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/emerging-techniques-speculative-decoding/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Optimize LLM inference speed using speculative decoding, Medusa, and lookahead techniques for real-time applications. | 19K | 99 | 2026-02-04 | [llm-optimization](llm-optimization.md), [performance](performance.md), [deployment](deployment.md), [llm](llm.md), [vllm](vllm.md), [medusa](medusa.md) |
| [fine-tuning-with-trl](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/post-training-trl-fine-tuning/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Fine-tune LLMs using reinforcement learning with TRL for SFT, DPO, PPO, and reward modeling. | 19K | 98 | 2026-02-04 | [llm-optimization](llm-optimization.md), [fine-tuning](fine-tuning.md), [reinforcement-learning](reinforcement-learning.md), [huggingface](huggingface.md), [transformers](transformers.md) |
| [agentic-eval](https://github.com/github/awesome-copilot/blob/main/skills/agentic-eval/SKILL.md) | [github/awesome-copilot](https://github.com/github/awesome-copilot) | Evaluate and improve AI agent outputs using self-critique, reflection loops, and LLM-as-judge systems. | 20K | 97 | 2026-02-04 | [eval](eval.md), [agents](agents.md), [llm-optimization](llm-optimization.md), [quality-management](quality-management.md), [testing](testing.md) |
| [humanizer-zh-tw](https://github.com/kevintsai1202/humanizer-zh-tw/blob/main/SKILL.md) | [kevintsai1202/humanizer-zh-tw](https://github.com/kevintsai1202/humanizer-zh-tw) | Remove AI-generated traces from text to make it sound more human-written. | 105 | 97 | 2026-01-20 | [writing](writing.md), [text-generation](text-generation.md), [humanizer](humanizer.md), [llm-optimization](llm-optimization.md) |
| [implementing-llms-litgpt](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/model-architecture-litgpt/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Implement and train LLMs using LitGPT with 20+ architectures like Llama, Gemma, Phi, Qwen, Mistral. | 19K | 96 | 2026-02-04 | [coding](coding.md), [llm-optimization](llm-optimization.md), [fine-tuning](fine-tuning.md), [llm](llm.md), [pytorch](pytorch.md) |
| [mamba-architecture](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/model-architecture-mamba/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Mamba architecture: State-space model with O(n) complexity, 5x faster inference, million-token sequences, no KV cache. | 19K | 96 | 2026-02-04 | [architecture](architecture.md), [llm-optimization](llm-optimization.md), [machine-learning](machine-learning.md), [transformers](transformers.md), [mamba](mamba.md) |
| [gguf-quantization](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/optimization-gguf/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Optimize LLM inference with GGUF format and llama.cpp quantization for CPU/GPU deployment. | 19K | 95 | 2026-02-04 | [llm-optimization](llm-optimization.md), [deployment](deployment.md), [gpu](gpu.md), [cpu](cpu.md) |
| [humanizer](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/productivity/humanizer/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Remove AI-generated writing signs from text to make it sound more natural. | 19K | 95 | 2026-02-04 | [writing](writing.md), [text-generation](text-generation.md), [humanizer](humanizer.md), [llm-optimization](llm-optimization.md) |
| [prompt-caching](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/prompt-caching/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Optimize LLM prompt caching with Anthropic, response caching, and CAG strategies. | 19K | 95 | 2026-02-04 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [cache](cache.md), [anthropic](anthropic.md), [cag](cag.md) |
| [sglang](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/inference-serving-sglang/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Fast structured generation and serving for LLMs with RadixAttention prefix caching, optimized for JSON/regex outputs and agentic workflows. | 19K | 95 | 2026-02-04 | [llm-optimization](llm-optimization.md), [text-generation](text-generation.md), [tooling](tooling.md), [vllm](vllm.md), [gpu](gpu.md) |
| [optimizing-attention-flash](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/optimization-flash-attention/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Optimizes transformer attention using Flash Attention for faster inference and reduced memory usage. | 19K | 94 | 2026-02-04 | [llm-optimization](llm-optimization.md), [performance](performance.md), [flash-attn](flash-attn.md), [pytorch](pytorch.md), [transformers](transformers.md) |
| [pyvene-interventions](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/mechanistic-interpretability-pyvene/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Guides causal interventions on PyTorch models using pyvene framework for causal tracing and activation patching. | 19K | 94 | 2026-02-04 | [machine-learning](machine-learning.md), [llm-optimization](llm-optimization.md), [pytorch](pytorch.md) |
| [quantizing-models-bitsandbytes](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/optimization-bitsandbytes/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Quantizes LLMs to 8-bit or 4-bit for memory reduction and faster inference. | 19K | 94 | 2026-02-04 | [llm-optimization](llm-optimization.md), [gpu](gpu.md), [huggingface](huggingface.md) |
| [axolotl](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/fine-tuning-axolotl/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Guidance for fine-tuning LLMs with Axolotl using YAML configs, LoRA/QLoRA, DPO/KTO/ORPO/GRPO, and multimodal support. | 19K | 93 | 2026-02-04 | [fine-tuning](fine-tuning.md), [llm-optimization](llm-optimization.md), [multimodal](multimodal.md), [yaml](yaml.md), [lora](lora.md) |
| [clip](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/multimodal-clip/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A vision-language model for image classification, matching, and retrieval without fine-tuning. | 19K | 93 | 2026-02-04 | [multimodal](multimodal.md), [vision-language](vision-language.md), [image-generation](image-generation.md), [text-to-image](text-to-image.md), [llm-optimization](llm-optimization.md) |
| [constitutional-ai](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/safety-alignment-constitutional-ai/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Training safe AI via self-improvement with supervised learning and RLAIF; powers Claude's safety system. | 19K | 93 | 2026-02-04 | [guardrails](guardrails.md), [llm-optimization](llm-optimization.md), [anthropic](anthropic.md), [claude](claude.md) |
| [openrlhf-training](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/post-training-openrlhf/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A high-performance RLHF framework using Ray and vLLM for large model training. | 19K | 93 | 2026-02-04 | [training](training.md), [llm-optimization](llm-optimization.md), [machine-learning](machine-learning.md), [ray](ray.md), [vllm](vllm.md) |
| [awq-quantization](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/optimization-awq/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Activation-aware weight quantization for 4-bit LLM compression with 3x speedup and minimal accuracy loss. | 19K | 92 | 2026-02-04 | [llm-optimization](llm-optimization.md), [deployment](deployment.md), [performance](performance.md), [gpu](gpu.md) |
| [behavioral-modes](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/behavioral-modes/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Adapts AI behavior based on task type using predefined operational modes. | 19K | 92 | 2026-02-04 | [behavioral-science](behavioral-science.md), [llm-optimization](llm-optimization.md), [agents](agents.md) |
| [blip-2-vision-language](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/multimodal-blip-2/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A vision-language model for image captioning, visual Q&A, and multimodal chat with zero-shot performance. | 19K | 92 | 2026-02-04 | [multimodal](multimodal.md), [vision-language](vision-language.md), [image-generation](image-generation.md), [text-generation](text-generation.md), [llm-optimization](llm-optimization.md) |
| [codex](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/development/codex/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A skill for using Codex CLI with GPT-5.2 for code analysis, refactoring, and automated editing. | 19K | 92 | 2026-02-04 | [coding](coding.md), [cli](cli.md), [codex](codex.md), [llm-optimization](llm-optimization.md) |
| [transformer-lens-interpretability](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/mechanistic-interpretability-transformer-lens/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A skill for mechanistic interpretability research using TransformerLens to inspect transformer internals. | 19K | 92 | 2026-02-04 | [analysis](analysis.md), [machine-learning](machine-learning.md), [transformers](transformers.md), [llm-optimization](llm-optimization.md) |
| [grpo-rl-training](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/post-training-grpo-rl-training/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Expert guidance for GRPO/RL fine-tuning with TRL for reasoning and task-specific model training. | 19K | 91 | 2026-02-04 | [fine-tuning](fine-tuning.md), [reinforcement-learning](reinforcement-learning.md), [llm-optimization](llm-optimization.md), [trl](trl.md), [grpo](grpo.md) |
| [gptq](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/optimization-gptq/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Post-training 4-bit quantization for LLMs with minimal accuracy loss, enabling deployment of large models on consumer GPUs. | 19K | 90 | 2026-02-04 | [llm-optimization](llm-optimization.md), [deployment](deployment.md), [fine-tuning](fine-tuning.md), [transformers](transformers.md), [peft](peft.md) |
| [nemo-guardrails](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/safety-alignment-nemo-guardrails/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | NVIDIA's runtime safety framework for LLM applications with features like jailbreak detection and PII filtering. | 19K | 90 | 2026-02-04 | [guardrails](guardrails.md), [llm-optimization](llm-optimization.md), [nvidia](nvidia.md), [gpu](gpu.md) |
| [simpo-training](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/post-training-simpo/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A simple and efficient method for LLM preference alignment without reference models. | 19K | 90 | 2026-02-04 | [llm-optimization](llm-optimization.md), [training](training.md), [fine-tuning](fine-tuning.md) |
| [promptify](https://github.com/intellectronica/agent-skills/blob/main/skills/promptify/SKILL.md) | [intellectronica/agent-skills](https://github.com/intellectronica/agent-skills) | Transforms user requests into precise AI prompts for better responses. | 173 | 90 | 2026-02-02 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [text-generation](text-generation.md), [ai](ai.md) |
| [hqq-quantization](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/optimization-hqq/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Quantize LLMs to 4/3/2-bit precision without calibration data, suitable for fast workflows with vLLM or HuggingFace. | 19K | 89 | 2026-02-04 | [llm-optimization](llm-optimization.md), [vllm](vllm.md), [huggingface-transformers](huggingface-transformers.md) |
| [rwkv-architecture](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/model-architecture-rwkv/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | RWKV is a hybrid RNN+Transformer architecture with O(n) inference, supporting linear time and infinite context. | 19K | 89 | 2026-02-04 | [architecture](architecture.md), [llm-optimization](llm-optimization.md), [transformers](transformers.md), [rnn](rnn.md), [linux-foundation](linux-foundation.md) |
| [nowait-reasoning-optimizer](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/productivity/nowait/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Optimizes reasoning in LLMs using the NOWAIT technique, reducing token usage by 27-51% while maintaining accuracy. | 19K | 87 | 2026-02-04 | [llm-optimization](llm-optimization.md), [reasoning](reasoning.md), [optimization](optimization.md), [qwen3](qwen3.md), [phi4-reasoning](phi4-reasoning.md) |
| [rag-engineer](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/rag-engineer/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Build Retrieval-Augmented Generation systems with expertise in embeddings, vector databases, and retrieval optimization. | 19K | 87 | 2026-02-04 | [rag](rag.md), [llm-optimization](llm-optimization.md), [embedding](embedding.md), [vector-database](vector-database.md), [semantic-search](semantic-search.md) |
| [rag-implementation](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/rag-implementation/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Implement Retrieval-Augmented Generation with chunking, embeddings, vector stores, and retrieval optimization. | 19K | 81 | 2026-02-04 | [rag](rag.md), [embedding](embedding.md), [vector-search](vector-search.md), [llm-optimization](llm-optimization.md), [knowledge-base](knowledge-base.md) |
| [hypogenic](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/scientific/hypogenic/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Generates and tests scientific hypotheses using LLMs from datasets and literature. | 19K | 80 | 2026-02-04 | [literature-review](literature-review.md), [data-analysis](data-analysis.md), [statistical-analysis](statistical-analysis.md), [llm-optimization](llm-optimization.md), [ai](ai.md), [research-paper](research-paper.md) |
| [skill-evolution-manager](https://github.com/kkkkhazix/khazix-skills/blob/main/skill-evolution-manager/SKILL.md) | [kkkkhazix/khazix-skills](https://github.com/kkkkhazix/khazix-skills) | Manages skill evolution by summarizing and iterating skills based on user feedback and conversation content. | 793 | 80 | 2026-01-22 | [skill-creation](skill-creation.md), [skill-management](skill-management.md), [llm-optimization](llm-optimization.md) |
| [ai-product](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/business-marketing/ai-product/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | An AI-powered product skill covering LLM integration, RAG, prompt engineering, and cost optimization. | 19K | 78 | 2026-02-04 | [llm-optimization](llm-optimization.md), [rag](rag.md), [prompting](prompting.md), [ai](ai.md), [architecture](architecture.md) |
| [docs-seeker](https://github.com/mrgoonie/claudekit-skills/blob/main/.claude/skills/docs-seeker/SKILL.md) | [mrgoonie/claudekit-skills](https://github.com/mrgoonie/claudekit-skills) | A skill for finding technical documentation using LLMs, GitHub repos, and parallel exploration. | 1.6K | 76 | 2026-02-03 | [web-research](web-research.md), [documentation](documentation.md), [llm-optimization](llm-optimization.md), [search](search.md) |
| [cc-skill-continuous-learning](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/development/cc-skill-continuous-learning/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A skill for continuous learning and LLM optimization. | 19K | 71 | 2026-02-04 | [continuous-learning](continuous-learning.md), [llm-optimization](llm-optimization.md), [tooling](tooling.md) |
| [senior-prompt-engineer](https://github.com/alirezarezvani/claude-skills/blob/main/engineering-team/senior-prompt-engineer/SKILL.md) | [alirezarezvani/claude-skills](https://github.com/alirezarezvani/claude-skills) | A skill for optimizing prompts, designing prompt templates, evaluating LLM outputs, and building agentic systems. | 1.6K | 71 | 2026-02-03 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [evaluation](evaluation.md), [rag](rag.md), [agents](agents.md), [workflows](workflows.md) |
| [qiskit](https://github.com/k-dense-ai/claude-scientific-skills/blob/main/scientific-skills/qiskit/SKILL.md) | [k-dense-ai/claude-scientific-skills](https://github.com/k-dense-ai/claude-scientific-skills) | A skill for using IBM's quantum computing framework, Qiskit, for quantum error mitigation and enterprise quantum computing. | 7.8K | 70 | 2026-02-04 | [quantum-computing](quantum-computing.md), [machine-learning](machine-learning.md), [llm-optimization](llm-optimization.md), [ibm](ibm.md), [hardware](hardware.md) |
| [building-with-llms](https://github.com/refoundai/lenny-skills/blob/main/skills/building-with-llms/SKILL.md) | [refoundai/lenny-skills](https://github.com/refoundai/lenny-skills) | A skill for building effective AI applications, including prompt engineering, RAG, agent design, and evaluation. | 66 | 69 | 2026-01-31 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [rag](rag.md), [agents](agents.md), [eval](eval.md), [tooling](tooling.md) |
| [voice-agents](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/voice-agents/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A skill for building voice agents with low-latency speech-to-speech or pipeline architectures. | 19K | 68 | 2026-02-04 | [agents](agents.md), [audio-generation](audio-generation.md), [text-to-speech](text-to-speech.md), [speech](speech.md), [realtime](realtime.md), [llm-optimization](llm-optimization.md) |
| [tavily-api-expert](https://github.com/tavily-ai/tavily-plugins) | [tavily-ai/tavily-plugins](https://github.com/tavily-ai/tavily-plugins) | An expert skill for leveraging the Tavily API to perform advanced web research and retrieve relevant information. | 0 | 63 |  | [web-research](web-research.md), [api](api.md), [llm-optimization](llm-optimization.md) |
| [geo-fundamentals](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/utilities/geo-fundamentals/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Optimizes AI search engines like ChatGPT, Claude, and Perplexity with generative engine techniques. | 19K | 62 | 2026-02-04 | [llm-optimization](llm-optimization.md), [text-generation](text-generation.md), [chatgpt](chatgpt.md), [claude](claude.md), [perplexity](perplexity.md) |
| [ai-engineer](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/ai-engineer/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Build production-ready LLM applications, advanced RAG systems, and intelligent agents with vector search and multimodal AI. | 6.9K | 61 | 2026-02-03 | [agents](agents.md), [rag](rag.md), [llm-optimization](llm-optimization.md), [multimodal](multimodal.md), [vector-search](vector-search.md), [enterprise](enterprise.md) |
| [voice-ai-engine-development](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/voice-ai-engine-development/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Develop real-time conversational AI voice engines with LLM agents, TTS, and streaming capabilities. | 6.9K | 57 | 2026-02-03 | [audio-generation](audio-generation.md), [text-to-speech](text-to-speech.md), [transcription](transcription.md), [llm-optimization](llm-optimization.md), [agents](agents.md), [streaming](streaming.md) |
| [aeo-optimization](https://github.com/alinaqi/claude-bootstrap/blob/main/skills/aeo-optimization/SKILL.md) | [alinaqi/claude-bootstrap](https://github.com/alinaqi/claude-bootstrap) | Optimizes AI engine with semantic triples and content clusters for better citations. | 474 | 57 | 2026-01-20 | [llm-optimization](llm-optimization.md), [content-creation](content-creation.md), [semantic-search](semantic-search.md) |
| [anti-slop](https://github.com/rand/cc-polymath/blob/main/skills/anti-slop/SKILL.md) | [rand/cc-polymath](https://github.com/rand/cc-polymath) | Detects and eliminates generic, low-quality AI-generated patterns in text, code, and design to improve content quality. | 65 | 57 | 2026-02-03 | [quality-management](quality-management.md), [text-generation](text-generation.md), [llm-optimization](llm-optimization.md), [content-creation](content-creation.md) |
| [prompt-optimizer](https://github.com/daymade/claude-code-skills/blob/main/prompt-optimizer/SKILL.md) | [daymade/claude-code-skills](https://github.com/daymade/claude-code-skills) | Optimize vague prompts into precise specifications using EARS methodology. | 540 | 55 | 2026-01-29 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [optimization](optimization.md) |
| [stop-slop](https://github.com/hardikpandya/stop-slop/blob/main/SKILL.md) | [hardikpandya/stop-slop](https://github.com/hardikpandya/stop-slop) | Remove predictable AI writing patterns from text to improve human-like quality. | 274 | 49 | 2026-01-13 | [writing](writing.md), [text-generation](text-generation.md), [llm-optimization](llm-optimization.md), [prose](prose.md) |
| [and-token-efficient-refinement](https://github.com/gocallum/nextjs16-agent-skills) | [gocallum/nextjs16-agent-skills](https://github.com/gocallum/nextjs16-agent-skills) | Optimizes LLM prompts for better token efficiency and refined outputs. | 11 | 49 | 2026-01-21 | [llm-optimization](llm-optimization.md), [text-generation](text-generation.md), [agents](agents.md) |
| [grepai-languages](https://github.com/yoanbernabeu/grepai-skills/blob/main/skills/advanced/grepai-languages/SKILL.md) | [yoanbernabeu/grepai-skills](https://github.com/yoanbernabeu/grepai-skills) | This skill helps understand supported programming languages in GrepAI for indexing and tracing. | 7 | 49 | 2026-02-01 | [llm-optimization](llm-optimization.md), [tooling](tooling.md), [code](code.md) |
| [context-manager](https://github.com/eddiebe147/claude-settings/blob/main/skills/context-manager/SKILL.md) | [eddiebe147/claude-settings](https://github.com/eddiebe147/claude-settings) | Manages conversation context and memory for optimal AI performance. | 15 | 47 | 2026-01-22 | [context-management](context-management.md), [llm-optimization](llm-optimization.md), [session-management](session-management.md), [memory](memory.md) |
| [llm-application-dev](https://github.com/skillcreatorai/ai-agent-skills/blob/main/skills/llm-application-dev/SKILL.md) | [skillcreatorai/ai-agent-skills](https://github.com/skillcreatorai/ai-agent-skills) | Build applications using LLMs with prompt engineering, RAG patterns, and LLM integration for AI features, chatbots, and automation. | 675 | 46 | 2026-01-23 | [prompting](prompting.md), [rag](rag.md), [llm-optimization](llm-optimization.md), [llm](llm.md), [ai](ai.md) |
| [llm-prompt-optimizer](https://github.com/eddiebe147/claude-settings/blob/main/skills/llm-prompt-optimizer/SKILL.md) | [eddiebe147/claude-settings](https://github.com/eddiebe147/claude-settings) | Optimize LLM prompts for better outputs through systematic analysis and refinement. | 15 | 45 | 2026-01-22 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [optimization](optimization.md) |
| [rag-pipeline-builder](https://github.com/eddiebe147/claude-settings/blob/main/skills/rag-pipeline-builder/SKILL.md) | [eddiebe147/claude-settings](https://github.com/eddiebe147/claude-settings) | Build RAG systems to ground LLM responses in your data. | 15 | 45 | 2026-01-22 | [rag](rag.md), [llm-optimization](llm-optimization.md), [data-management](data-management.md) |
| [nlp-pipeline-builder](https://github.com/eddiebe147/claude-settings/blob/main/skills/nlp-pipeline-builder/SKILL.md) | [eddiebe147/claude-settings](https://github.com/eddiebe147/claude-settings) | Build NLP pipelines for text analysis and understanding. | 15 | 44 | 2026-01-22 | [natural-language-processing](natural-language-processing.md), [machine-learning](machine-learning.md), [data-analysis](data-analysis.md), [text-generation](text-generation.md), [llm-optimization](llm-optimization.md) |
| [prompt-engineer](https://github.com/eddiebe147/claude-settings/blob/main/skills/prompt-engineer/SKILL.md) | [eddiebe147/claude-settings](https://github.com/eddiebe147/claude-settings) | Optimize AI interactions through effective prompt engineering. | 15 | 42 | 2026-01-22 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [ai](ai.md) |
| [workflow-designer](https://github.com/eddiebe147/claude-settings/blob/main/skills/workflow-designer/SKILL.md) | [eddiebe147/claude-settings](https://github.com/eddiebe147/claude-settings) | Design and optimize AI-powered workflows for complex tasks. | 15 | 42 | 2026-01-22 | [workflows](workflows.md), [automation](automation.md), [llm-optimization](llm-optimization.md) |
| [dspy-ruby](https://github.com/everyinc/compound-engineering-plugin/blob/main/plugins/compound-engineering/skills/dspy-ruby/SKILL.md) | [everyinc/compound-engineering-plugin](https://github.com/everyinc/compound-engineering-plugin) | A skill for building type-safe, composable LLM applications in Ruby with DSPy.rb framework. | 7.1K | 40 | 2026-02-02 | [llm-optimization](llm-optimization.md), [code-generation](code-generation.md), [ruby](ruby.md), [prompting](prompting.md) |
| [llm-patterns](https://github.com/alinaqi/claude-bootstrap/blob/main/skills/llm-patterns/SKILL.md) | [alinaqi/claude-bootstrap](https://github.com/alinaqi/claude-bootstrap) | This skill focuses on AI-first application patterns, LLM testing, and prompt management. | 474 | 40 | 2026-01-20 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [testing](testing.md), [llm](llm.md) |
| [web-content](https://github.com/alinaqi/claude-bootstrap/blob/main/skills/web-content/SKILL.md) | [alinaqi/claude-bootstrap](https://github.com/alinaqi/claude-bootstrap) | Optimize web content for SEO and AI discovery with schema and ChatGPT/Perplexity enhancements. | 474 | 40 | 2026-01-20 | [seo](seo.md), [llm-optimization](llm-optimization.md), [schema](schema.md), [chatgpt](chatgpt.md), [perplexity](perplexity.md) |
| [fine-tuning-assistant](https://github.com/eddiebe147/claude-settings/blob/main/skills/fine-tuning-assistant/SKILL.md) | [eddiebe147/claude-settings](https://github.com/eddiebe147/claude-settings) | A guide for fine-tuning language models to achieve customized AI performance. | 15 | 40 | 2026-01-22 | [llm-optimization](llm-optimization.md), [fine-tuning](fine-tuning.md), [machine-learning](machine-learning.md), [model-monitoring](model-monitoring.md) |
| [best-practices](https://github.com/skillcreatorai/ai-agent-skills/blob/main/skills/best-practices/SKILL.md) | [skillcreatorai/ai-agent-skills](https://github.com/skillcreatorai/ai-agent-skills) | Optimizes vague prompts into structured Claude Code prompts with verification and constraints. | 675 | 39 | 2026-01-23 | [best-practices](best-practices.md), [prompting](prompting.md), [llm-optimization](llm-optimization.md) |
| [claude-md-progressive-disclosurer](https://github.com/daymade/claude-code-skills/blob/main/claude-md-progressive-disclosurer/SKILL.md) | [daymade/claude-code-skills](https://github.com/daymade/claude-code-skills) | Optimizes CLAUDE.md files using progressive disclosure to improve LLM efficiency. | 540 | 39 | 2026-01-29 | [llm-optimization](llm-optimization.md), [context-management](context-management.md), [markdown](markdown.md), [claude](claude.md) |
| [context-engineering](https://github.com/siviter-xyz/dot-agent/blob/main/skills/context-engineering/SKILL.md) | [siviter-xyz/dot-agent](https://github.com/siviter-xyz/dot-agent) | Master context engineering for AI agent systems including architecture design, debugging, and optimization. | 2 | 38 | 2026-01-20 | [context-management](context-management.md), [llm-optimization](llm-optimization.md), [agents](agents.md), [architecture](architecture.md), [debugging](debugging.md) |
| [pydantic-ai-model-integration](https://github.com/existential-birds/beagle/blob/main/skills/pydantic-ai-model-integration/SKILL.md) | [existential-birds/beagle](https://github.com/existential-birds/beagle) | Configure LLM providers, use fallback models, handle streaming, and manage model settings in PydanticAI. | 16 | 36 | 2026-02-01 | [configuration](configuration.md), [api](api.md), [llm-optimization](llm-optimization.md), [pydantic](pydantic.md) |
| [self-improving-agent](https://github.com/charon-fan/agent-playbook/blob/main/skills/self-improving-agent/SKILL.md) | [charon-fan/agent-playbook](https://github.com/charon-fan/agent-playbook) | A universal self-improving agent that evolves through multi-memory architecture and hooks-based correction. | 4 | 34 | 2026-01-22 | [agents](agents.md), [continuous-learning](continuous-learning.md), [llm-optimization](llm-optimization.md), [multi-agent](multi-agent.md), [code-generation](code-generation.md) |
| [prompt-engineering](https://github.com/neolabhq/context-engineering-kit/blob/master/plugins/customaize-agent/skills/prompt-engineering/SKILL.md) | [neolabhq/context-engineering-kit](https://github.com/neolabhq/context-engineering-kit) | Optimize prompts and improve LLM outputs for agent interactions and sub-agent tasks. | 386 | 33 | 2026-02-04 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [text-generation](text-generation.md), [llm](llm.md) |
| [llm-integration](https://github.com/martinholovsky/claude-skills-generator/blob/main/skills/llm-integration/SKILL.md) | [martinholovsky/claude-skills-generator](https://github.com/martinholovsky/claude-skills-generator) | Integrates local LLMs with security optimizations and vulnerability protection. | 21 | 32 | 2025-12-06 | [llm-optimization](llm-optimization.md), [prompting](prompting.md), [ollama](ollama.md), [llm](llm.md) |
| [prompt-engineering](https://github.com/martinholovsky/claude-skills-generator/blob/main/skills/prompt-engineering/SKILL.md) | [martinholovsky/claude-skills-generator](https://github.com/martinholovsky/claude-skills-generator) | Expert skill for prompt engineering, secure prompt construction, and LLM task orchestration. | 21 | 32 | 2025-12-06 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [task-management](task-management.md), [llm](llm.md), [ai](ai.md) |
| [behavioral-modes](https://github.com/vudovn/antigravity-kit/blob/main/.agent/skills/behavioral-modes/SKILL.md) | [vudovn/antigravity-kit](https://github.com/vudovn/antigravity-kit) | Adapts AI behavior based on task type using predefined operational modes. | 4.1K | 31 | 2026-02-01 | [behavioral-science](behavioral-science.md), [llm-optimization](llm-optimization.md), [agents](agents.md) |
| [geo-fundamentals](https://github.com/vudovn/antigravity-kit/blob/main/.agent/skills/geo-fundamentals/SKILL.md) | [vudovn/antigravity-kit](https://github.com/vudovn/antigravity-kit) | Optimizes AI search engines like ChatGPT, Claude, and Perplexity with generative engine techniques. | 4.1K | 31 | 2026-02-01 | [llm-optimization](llm-optimization.md), [text-generation](text-generation.md), [chatgpt](chatgpt.md), [claude](claude.md), [perplexity](perplexity.md) |
| [context-optimization](https://github.com/shipshitdev/library/blob/master/skills/context-optimization/SKILL.md) | [shipshitdev/library](https://github.com/shipshitdev/library) | Optimize context capacity for LLM agents to improve performance and reduce costs. | 4 | 31 | 2026-01-25 | [context-management](context-management.md), [llm-optimization](llm-optimization.md), [optimization](optimization.md) |
| [prompt-analyzer](https://github.com/huangserva/skill-prompt-generator/blob/main/.claude/skills/prompt-analyzer/SKILL.md) | [huangserva/skill-prompt-generator](https://github.com/huangserva/skill-prompt-generator) | Analyze prompts, compare differences, and recommend similar prompts with element statistics. | 986 | 30 | 2026-01-14 | [prompting](prompting.md), [analysis](analysis.md), [llm-optimization](llm-optimization.md) |
| [universal-learner](https://github.com/huangserva/skill-prompt-generator/blob/main/.claude/skills/universal-learner/SKILL.md) | [huangserva/skill-prompt-generator](https://github.com/huangserva/skill-prompt-generator) | A universal learner that extracts reusable elements from prompts and accumulates knowledge automatically. | 986 | 30 | 2026-01-14 | [llm-optimization](llm-optimization.md), [knowledge-base](knowledge-base.md), [continuous-learning](continuous-learning.md), [prompting](prompting.md) |
| [axiom-foundation-models](https://github.com/charleswiltgen/axiom/blob/main/.claude-plugin/plugins/axiom/skills/axiom-foundation-models/SKILL.md) | [charleswiltgen/axiom](https://github.com/charleswiltgen/axiom) | Optimizes on-device AI implementation with Apple's Foundation Models framework, preventing context overflow and UI blocking. | 392 | 30 | 2026-02-03 | [context-management](context-management.md), [llm-optimization](llm-optimization.md), [apple](apple.md), [ios](ios.md), [macos](macos.md) |
| [context-network](https://github.com/jwynia/agent-skills/blob/main/skills/general/meta/context-network/SKILL.md) | [jwynia/agent-skills](https://github.com/jwynia/agent-skills) | Manage and evolve context networks for LLM agents across their lifecycle. | 13 | 30 | 2026-02-04 | [context-management](context-management.md), [llm-optimization](llm-optimization.md), [agent-execution](agent-execution.md) |
| [valyu-best-practices](https://github.com/valyuai/skills/blob/main/valyu-search/valyu-best-practices/SKILL.md) | [valyuai/skills](https://github.com/valyuai/skills) | A Valyu API toolkit for AI agents to perform real-time web, academic, and financial research with AI-powered answers and citations. | 7 | 30 | 2026-01-21 | [api](api.md), [web-research](web-research.md), [llm-optimization](llm-optimization.md), [best-practices](best-practices.md), [tooling](tooling.md) |
| [agent-orchestration-improve-agent](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/agent-orchestration-improve-agent/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Improve agent performance through analysis and iterative refinement. | 6.9K | 29 | 2026-02-03 | [agents](agents.md), [performance](performance.md), [optimization](optimization.md), [llm-optimization](llm-optimization.md), [prompting](prompting.md) |
| [intelligent-prompt-generator](https://github.com/huangserva/skill-prompt-generator/blob/main/.claude/skills/intelligent-prompt-generator/SKILL.md) | [huangserva/skill-prompt-generator](https://github.com/huangserva/skill-prompt-generator) | An intelligent prompt generator supporting multiple modes like portrait, cross-domain, and design with semantic understanding and reasoning. | 986 | 29 | 2026-01-14 | [prompting](prompting.md), [text-generation](text-generation.md), [llm-optimization](llm-optimization.md), [gpt](gpt.md), [ai](ai.md) |
| [promptfoo-evaluation](https://github.com/daymade/claude-code-skills/blob/main/promptfoo-evaluation/SKILL.md) | [daymade/claude-code-skills](https://github.com/daymade/claude-code-skills) | Configure and run LLM evaluations using the Promptfoo framework. | 540 | 29 | 2026-01-29 | [eval](eval.md), [llm-optimization](llm-optimization.md), [prompting](prompting.md), [promptfoo](promptfoo.md), [llm](llm.md) |
| [thought-based-reasoning](https://github.com/neolabhq/context-engineering-kit/blob/master/plugins/customaize-agent/skills/thought-based-reasoning/SKILL.md) | [neolabhq/context-engineering-kit](https://github.com/neolabhq/context-engineering-kit) | A skill for complex reasoning tasks using Chain-of-Thought and related prompting techniques. | 386 | 29 | 2026-02-04 | [prompting](prompting.md), [reasoning](reasoning.md), [llm-optimization](llm-optimization.md), [chain-of-thought](chain-of-thought.md), [multi-step-arithmetic](multi-step-arithmetic.md) |
| [creative-intelligence](https://github.com/aj-geddes/claude-code-bmad-skills) | [aj-geddes/claude-code-bmad-skills](https://github.com/aj-geddes/claude-code-bmad-skills) | A skill for enhancing creative intelligence through LLM prompting and optimization. | 229 | 29 | 2026-01-01 | [llm-optimization](llm-optimization.md), [text-generation](text-generation.md), [agents](agents.md) |
| [ai-prompt-engineering](https://github.com/vasilyu1983/ai-agents-public/blob/main/frameworks/shared-skills/skills/ai-prompt-engineering/SKILL.md) | [vasilyu1983/ai-agents-public](https://github.com/vasilyu1983/ai-agents-public) | Operational prompt engineering for production LLM applications with structured outputs, RAG, tool workflows, and safety measures. | 29 | 29 | 2026-01-26 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [api](api.md), [codex](codex.md), [claude](claude.md), [gemini](gemini.md) |
| [marketing-ai-search-optimization](https://github.com/vasilyu1983/ai-agents-public/blob/main/frameworks/shared-skills/skills/marketing-ai-search-optimization/SKILL.md) | [vasilyu1983/ai-agents-public](https://github.com/vasilyu1983/ai-agents-public) | Optimize visibility in AI search engines like ChatGPT, Perplexity, and Gemini using GEO strategies. | 29 | 29 | 2026-01-26 | [seo](seo.md), [marketing](marketing.md), [llm-optimization](llm-optimization.md), [chatgpt](chatgpt.md), [gemini](gemini.md), [perplexity](perplexity.md) |
| [review-skill-improver](https://github.com/existential-birds/beagle/blob/main/skills/review-skill-improver/SKILL.md) | [existential-birds/beagle](https://github.com/existential-birds/beagle) | Improves review skills by analyzing feedback logs for patterns and suggestions. | 16 | 28 | 2026-02-01 | [review](review.md), [analysis](analysis.md), [feedback](feedback.md), [llm-optimization](llm-optimization.md) |
| [advanced-evaluation](https://github.com/shipshitdev/library/blob/master/skills/advanced-evaluation/SKILL.md) | [shipshitdev/library](https://github.com/shipshitdev/library) | Master LLM-as-a-Judge evaluation techniques including direct scoring, pairwise comparison, rubric generation, and bias mitigation. | 4 | 28 | 2026-01-25 | [eval](eval.md), [llm-optimization](llm-optimization.md), [agents](agents.md) |
| [context-fundamentals](https://github.com/shipshitdev/library/blob/master/skills/context-fundamentals/SKILL.md) | [shipshitdev/library](https://github.com/shipshitdev/library) | Understand context components and constraints in agent systems for architecture design and optimization. | 4 | 28 | 2026-01-25 | [context-management](context-management.md), [architecture](architecture.md), [agents](agents.md), [llm-optimization](llm-optimization.md) |
| [axiom-foundation-models-diag](https://github.com/charleswiltgen/axiom/blob/main/.claude-plugin/plugins/axiom/skills/axiom-foundation-models-diag/SKILL.md) | [charleswiltgen/axiom](https://github.com/charleswiltgen/axiom) | Debug issues with foundation models including context limits, guardrail violations, and generation problems. | 392 | 27 | 2026-02-03 | [debugging](debugging.md), [guardrails](guardrails.md), [llm-optimization](llm-optimization.md), [foundation-models](foundation-models.md) |
| [anthropic-architect](https://github.com/jamesrochabrun/skills/blob/main/skills/anthropic-architect/SKILL.md) | [jamesrochabrun/skills](https://github.com/jamesrochabrun/skills) | Helps determine the best Anthropic architecture for a project by analyzing requirements and recommending optimal combinations of skills, age | 38 | 26 | 2026-01-14 | [architecture](architecture.md), [analysis](analysis.md), [anthropic](anthropic.md), [llm-optimization](llm-optimization.md) |
| [model-quantization](https://github.com/martinholovsky/claude-skills-generator/blob/main/skills/model-quantization/SKILL.md) | [martinholovsky/claude-skills-generator](https://github.com/martinholovsky/claude-skills-generator) | Optimize and quantize AI models for efficient deployment in resource-constrained environments. | 21 | 26 | 2025-12-06 | [llm-optimization](llm-optimization.md), [optimization](optimization.md), [model-monitoring](model-monitoring.md), [gguf](gguf.md), [gpu](gpu.md) |
| [oracle](https://github.com/trancong12102/agentskills) | [trancong12102/agentskills](https://github.com/trancong12102/agentskills) | An LLM skill for Oracle database interaction and optimization. | 3 | 26 | 2026-01-29 | [llm-optimization](llm-optimization.md), [tooling](tooling.md), [agents](agents.md) |
| [ralph](https://github.com/yeachan-heo/oh-my-claudecode/blob/main/skills/ralph/SKILL.md) | [yeachan-heo/oh-my-claudecode](https://github.com/yeachan-heo/oh-my-claudecode) | A self-referential loop skill for task completion with architect verification. | 4.5K | 25 | 2026-02-04 | [agents](agents.md), [architecture](architecture.md), [llm-optimization](llm-optimization.md) |
| [anthropic-sdk](https://github.com/bobmatnyc/claude-mpm-skills/blob/main/toolchains/ai/sdks/anthropic/SKILL.md) | [bobmatnyc/claude-mpm-skills](https://github.com/bobmatnyc/claude-mpm-skills) | Official Anthropic SDK for Claude AI with chat, streaming, function calling, and vision capabilities. | 11 | 25 | 2026-02-01 | [api](api.md), [ai-sdk](ai-sdk.md), [anthropic](anthropic.md), [claude](claude.md), [llm-optimization](llm-optimization.md), [tooling](tooling.md) |
| [dspy-framework](https://github.com/bobmatnyc/claude-mpm-skills/blob/main/toolchains/ai/frameworks/dspy/SKILL.md) | [bobmatnyc/claude-mpm-skills](https://github.com/bobmatnyc/claude-mpm-skills) | A declarative framework for automatic prompt optimization treating prompts as code with evaluation and compilers. | 11 | 25 | 2026-02-01 | [prompting](prompting.md), [code-generation](code-generation.md), [llm-optimization](llm-optimization.md), [framework](framework.md), [declarative](declarative.md) |
| [openspec](https://github.com/itechmeat/llm-code/blob/master/skills/openspec/SKILL.md) | [itechmeat/llm-code](https://github.com/itechmeat/llm-code) | An LLM optimization and prompting skill for better model performance. | 3 | 25 | 2026-02-01 | [llm-optimization](llm-optimization.md), [tooling](tooling.md), [agents](agents.md) |
| [prompt-engineering-patterns](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/prompt-engineering-patterns/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Master advanced prompt engineering techniques for maximizing LLM performance, reliability, and controllability in production. | 6.9K | 24 | 2026-02-03 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [best-practices](best-practices.md), [llm](llm.md) |
| [prompt-extractor](https://github.com/huangserva/skill-prompt-generator) | [huangserva/skill-prompt-generator](https://github.com/huangserva/skill-prompt-generator) | Extracts prompts from text for LLM usage. | 986 | 24 | 2026-01-14 | [prompting](prompting.md), [text-generation](text-generation.md), [llm-optimization](llm-optimization.md) |
| [prompt-generator](https://github.com/huangserva/skill-prompt-generator) | [huangserva/skill-prompt-generator](https://github.com/huangserva/skill-prompt-generator) | Generates optimized prompts for LLMs to improve response quality and relevance. | 986 | 24 | 2026-01-14 | [prompting](prompting.md), [text-generation](text-generation.md), [llm-optimization](llm-optimization.md) |
| [prompt-xray](https://github.com/huangserva/skill-prompt-generator) | [huangserva/skill-prompt-generator](https://github.com/huangserva/skill-prompt-generator) | Analyze and optimize prompts for LLMs with detailed feedback. | 986 | 24 | 2026-01-14 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [tooling](tooling.md) |
| [context-engineering](https://github.com/neolabhq/context-engineering-kit/blob/master/plugins/customaize-agent/skills/context-engineering/SKILL.md) | [neolabhq/context-engineering-kit](https://github.com/neolabhq/context-engineering-kit) | Optimize agent system prompts by understanding context components and constraints. | 386 | 24 | 2026-02-04 | [context-management](context-management.md), [prompting](prompting.md), [agents](agents.md), [llm-optimization](llm-optimization.md) |
| [code-explanation](https://github.com/nickcrew/claude-ctx-plugin/blob/main/skills/code-explanation/SKILL.md) | [nickcrew/claude-ctx-plugin](https://github.com/nickcrew/claude-ctx-plugin) | Explains code, concepts, or system behavior to a specific audience level with structured workflow and depth control. | 7 | 24 | 2026-01-30 | [explanation](explanation.md), [code-analysis](code-analysis.md), [audience-analysis](audience-analysis.md), [llm-optimization](llm-optimization.md), [best-practices](best-practices.md) |
| [prompt-master](https://github.com/huangserva/skill-prompt-generator) | [huangserva/skill-prompt-generator](https://github.com/huangserva/skill-prompt-generator) | A skill for mastering prompts and optimizing LLM interactions. | 986 | 23 | 2026-01-14 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [tooling](tooling.md) |
| [anthropic-prompt-engineer](https://github.com/jamesrochabrun/skills/blob/main/skills/anthropic-prompt-engineer/SKILL.md) | [jamesrochabrun/skills](https://github.com/jamesrochabrun/skills) | Master Anthropic's prompt engineering techniques for Claude AI models. | 38 | 23 | 2026-01-14 | [prompting](prompting.md), [best-practices](best-practices.md), [llm-optimization](llm-optimization.md), [anthropic](anthropic.md), [claude](claude.md) |
| [openai-prompt-engineer](https://github.com/jamesrochabrun/skills/blob/main/skills/openai-prompt-engineer/SKILL.md) | [jamesrochabrun/skills](https://github.com/jamesrochabrun/skills) | Optimize prompts for OpenAI GPT-5 and other LLMs using advanced techniques like chain-of-thought and few-shot prompting. | 38 | 23 | 2026-01-14 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [best-practices](best-practices.md), [openai](openai.md), [gpt-5](gpt-5.md) |
| [ai-llm](https://github.com/vasilyu1983/ai-agents-public/blob/main/frameworks/shared-skills/skills/ai-llm/SKILL.md) | [vasilyu1983/ai-agents-public](https://github.com/vasilyu1983/ai-agents-public) | A production LLM engineering skill covering strategy selection, dataset design, PEFT/LoRA, evaluation workflows, and deployment. | 29 | 23 | 2026-01-26 | [llm-optimization](llm-optimization.md), [prompting](prompting.md), [rag](rag.md), [fine-tuning](fine-tuning.md), [evaluation](evaluation.md), [deployment](deployment.md) |
| [humanizer](https://github.com/shipshitdev/library/blob/master/skills/humanizer/SKILL.md) | [shipshitdev/library](https://github.com/shipshitdev/library) | Remove AI writing patterns to make text sound more natural and human. | 4 | 23 | 2026-01-25 | [writing](writing.md), [text-generation](text-generation.md), [llm-optimization](llm-optimization.md), [humanizer](humanizer.md) |
| [token-efficiency](https://github.com/delphine-l/claude_global/blob/main/skills/claude-meta/token-efficiency/SKILL.md) | [delphine-l/claude_global](https://github.com/delphine-l/claude_global) | Optimize token usage for Claude Code with efficient file reading, command execution, and output handling strategies. | 0 | 23 | 2026-01-24 | [cost-optimization](cost-optimization.md), [best-practices](best-practices.md), [llm-optimization](llm-optimization.md), [claude](claude.md), [bash](bash.md) |
| [ecomode](https://github.com/yeachan-heo/oh-my-claudecode/blob/main/skills/ecomode/SKILL.md) | [yeachan-heo/oh-my-claudecode](https://github.com/yeachan-heo/oh-my-claudecode) | A token-efficient model routing modifier for LLMs. | 4.5K | 22 | 2026-02-04 | [llm-optimization](llm-optimization.md), [tokenization](tokenization.md), [agents](agents.md) |
| [prompt-repetition](https://github.com/supercent-io/skills-template/blob/main/.agent-skills/agent-develop/prompt-repetition/SKILL.md) | [supercent-io/skills-template](https://github.com/supercent-io/skills-template) | Improves LLM accuracy through prompt repetition techniques, achieving significant performance gains on 67% of benchmarks. | 11 | 22 | 2026-01-28 | [llm-optimization](llm-optimization.md), [prompting](prompting.md), [performance](performance.md), [llm](llm.md), [ai-models](ai-models.md) |
| [geo-aeo-optimization](https://github.com/schwepps/skills/blob/main/geo-aeo-optimization/SKILL.md) | [schwepps/skills](https://github.com/schwepps/skills) | Optimize content for AI search engines and featured snippets using GEO and AEO techniques. | 3 | 22 | 2026-01-19 | [seo](seo.md), [optimization](optimization.md), [llm-optimization](llm-optimization.md), [chatgpt](chatgpt.md), [perplexity](perplexity.md), [claude](claude.md) |
| [llm-application-dev-prompt-optimize](https://github.com/sickn33/antigravity-awesome-skills/blob/main/skills/llm-application-dev-prompt-optimize/SKILL.md) | [sickn33/antigravity-awesome-skills](https://github.com/sickn33/antigravity-awesome-skills) | Optimize prompts for LLMs using constitutional AI, chain-of-thought reasoning, and model-specific techniques. | 6.9K | 21 | 2026-02-03 | [prompting](prompting.md), [llm-optimization](llm-optimization.md), [text-generation](text-generation.md), [llm](llm.md), [ai-models](ai-models.md) |
| [ultrapilot](https://github.com/yeachan-heo/oh-my-claudecode/blob/main/skills/ultrapilot/SKILL.md) | [yeachan-heo/oh-my-claudecode](https://github.com/yeachan-heo/oh-my-claudecode) | An autopilot skill with parallel execution and file ownership partitioning for efficient task management. | 4.5K | 21 | 2026-02-04 | [agents](agents.md), [automation](automation.md), [llm-optimization](llm-optimization.md), [tooling](tooling.md) |
| [agent-evaluation](https://github.com/neolabhq/context-engineering-kit/blob/master/plugins/customaize-agent/skills/agent-evaluation/SKILL.md) | [neolabhq/context-engineering-kit](https://github.com/neolabhq/context-engineering-kit) | Evaluate and improve Claude Code commands, skills, and agents for better prompt effectiveness and context engineering. | 386 | 21 | 2026-02-04 | [eval](eval.md), [llm-optimization](llm-optimization.md), [agents](agents.md), [claude](claude.md) |
| [foundation-models](https://github.com/johnrogers/claude-swift-engineering/blob/main/plugins/swift-engineering/skills/foundation-models/SKILL.md) | [johnrogers/claude-swift-engineering](https://github.com/johnrogers/claude-swift-engineering) | Implement on-device AI with Apple's Foundation Models framework for iOS 26+. | 91 | 21 | 2026-01-18 | [llm-optimization](llm-optimization.md), [foundation-models](foundation-models.md), [apple](apple.md), [ios](ios.md) |
