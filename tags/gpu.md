# Tag: gpu

- Back: [Tags](README.md)
- Tagged skills: 25

| Skill | Repo | Summary | ⭐ | ⬇️ | Updated | Tags |
| - | - | - | -: | -: | - | - |
| [webgpu](https://github.com/cazala/webgpu-skill/blob/main/SKILL.md) | [cazala/webgpu-skill](https://github.com/cazala/webgpu-skill) | A skill for WebGPU/WGSL guidance including initialization, pipelines, shader authoring, debugging, and performance optimization. | 10 | 349 | 2026-01-30 | [frontend](frontend.md), [graphics](graphics.md), [gpu](gpu.md), [shader](shader.md), [rendering](rendering.md), [performance](performance.md) |
| [modal-serverless-gpu](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/infrastructure-modal/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | A serverless GPU platform for running ML workloads without managing infrastructure. | 20K | 129 | 2026-02-15 | [machine-learning](machine-learning.md), [deployment](deployment.md), [serverless](serverless.md), [gpu](gpu.md) |
| [llama-cpp](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/inference-serving-llama-cpp/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Run LLM inference on CPU, Apple Silicon, and consumer GPUs with GGUF quantization support. | 20K | 128 | 2026-02-15 | [llm-optimization](llm-optimization.md), [deployment](deployment.md), [cpu](cpu.md), [gpu](gpu.md) |
| [training-llms-megatron](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/distributed-training-megatron-core/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Train large language models with NVIDIA Megatron-Core for high GPU efficiency and advanced parallelism. | 20K | 120 | 2026-02-15 | [llm-optimization](llm-optimization.md), [machine-learning](machine-learning.md), [training](training.md), [gpu](gpu.md), [megatron](megatron.md) |
| [peft-fine-tuning](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/fine-tuning-peft/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Efficient LLM fine-tuning with LoRA, QLoRA, and 25+ methods for limited GPU memory scenarios. | 20K | 119 | 2026-02-15 | [fine-tuning](fine-tuning.md), [llm-optimization](llm-optimization.md), [huggingface](huggingface.md), [transformers](transformers.md), [gpu](gpu.md) |
| [nemo-curator](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/data-processing-nemo-curator/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | GPU-accelerated data curation for LLM training with deduplication and quality filtering. | 20K | 116 | 2026-02-15 | [data-quality](data-quality.md), [data-management](data-management.md), [etl](etl.md), [gpu](gpu.md), [llm](llm.md) |
| [tensorrt-llm](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/inference-serving-tensorrt-llm/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Optimizes LLM inference using NVIDIA TensorRT for high throughput and low latency on A100/H100 GPUs. | 20K | 114 | 2026-02-15 | [llm-optimization](llm-optimization.md), [performance](performance.md), [deployment](deployment.md), [nvidia](nvidia.md), [gpu](gpu.md) |
| [faiss](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/rag-faiss/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Faiss is a library for efficient similarity search and clustering of dense vectors, supporting billions of vectors with GPU acceleration. | 20K | 113 | 2026-02-15 | [vector-search](vector-search.md), [machine-learning](machine-learning.md), [data-analysis](data-analysis.md), [gpu](gpu.md), [high-performance](high-performance.md) |
| [skypilot-multi-cloud-orchestration](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/infrastructure-skypilot/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Orchestrate ML workloads across multiple clouds with cost optimization and spot instance support. | 20K | 108 | 2026-02-15 | [machine-learning](machine-learning.md), [cost-optimization](cost-optimization.md), [orchestration](orchestration.md), [cloud](cloud.md), [gpu](gpu.md) |
| [gguf-quantization](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/optimization-gguf/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Optimize LLM inference with GGUF format and llama.cpp quantization for CPU/GPU deployment. | 20K | 105 | 2026-02-15 | [llm-optimization](llm-optimization.md), [deployment](deployment.md), [gpu](gpu.md), [cpu](cpu.md) |
| [lambda-labs-gpu-cloud](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/infrastructure-lambda-labs/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Provides reserved and on-demand GPU cloud instances for ML training and inference with SSH access and persistent filesystems. | 20K | 105 | 2026-02-15 | [machine-learning](machine-learning.md), [resource-management](resource-management.md), [gpu](gpu.md), [cloud](cloud.md) |
| [quantizing-models-bitsandbytes](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/optimization-bitsandbytes/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Quantizes LLMs to 8-bit or 4-bit for memory reduction and faster inference. | 20K | 105 | 2026-02-15 | [llm-optimization](llm-optimization.md), [gpu](gpu.md), [huggingface](huggingface.md) |
| [sglang](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/inference-serving-sglang/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Fast structured generation and serving for LLMs with RadixAttention prefix caching, optimized for JSON/regex outputs and agentic workflows. | 20K | 105 | 2026-02-15 | [llm-optimization](llm-optimization.md), [text-generation](text-generation.md), [tooling](tooling.md), [vllm](vllm.md), [gpu](gpu.md) |
| [nemo-guardrails](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/safety-alignment-nemo-guardrails/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | NVIDIA's runtime safety framework for LLM applications with features like jailbreak detection and PII filtering. | 20K | 99 | 2026-02-15 | [guardrails](guardrails.md), [llm-optimization](llm-optimization.md), [nvidia](nvidia.md), [gpu](gpu.md) |
| [awq-quantization](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/ai-research/optimization-awq/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Activation-aware weight quantization for 4-bit LLM compression with 3x speedup and minimal accuracy loss. | 20K | 97 | 2026-02-15 | [llm-optimization](llm-optimization.md), [deployment](deployment.md), [performance](performance.md), [gpu](gpu.md) |
| [modal](https://github.com/davila7/claude-code-templates/blob/main/cli-tool/components/skills/scientific/modal/SKILL.md) | [davila7/claude-code-templates](https://github.com/davila7/claude-code-templates) | Deploy Python code in the cloud with serverless containers, GPUs, and autoscaling for ML models and compute-intensive tasks. | 20K | 97 | 2026-02-15 | [deployment](deployment.md), [serverless](serverless.md), [cloud](cloud.md), [gpu](gpu.md), [autoscaling](autoscaling.md) |
| [hugging-face-model-trainer](https://github.com/huggingface/skills/blob/main/skills/hugging-face-model-trainer/SKILL.md) | [huggingface/skills](https://github.com/huggingface/skills) | Train or fine-tune language models using Hugging Face Jobs infrastructure with TRL methods. | 1.2K | 87 | 2026-02-06 | [machine-learning](machine-learning.md), [fine-tuning](fine-tuning.md), [huggingface](huggingface.md), [trl](trl.md), [gguf](gguf.md), [gpu](gpu.md) |
| [modal](https://github.com/k-dense-ai/claude-scientific-skills/blob/main/scientific-skills/modal/SKILL.md) | [k-dense-ai/claude-scientific-skills](https://github.com/k-dense-ai/claude-scientific-skills) | Deploy Python code in the cloud with serverless containers, GPUs, and autoscaling for ML models and compute-intensive tasks. | 7.8K | 73 | 2026-02-04 | [deployment](deployment.md), [serverless](serverless.md), [cloud](cloud.md), [gpu](gpu.md), [autoscaling](autoscaling.md) |
| [axiom-ios-graphics](https://github.com/charleswiltgen/axiom/blob/main/.claude-plugin/plugins/axiom/skills/axiom-ios-graphics/SKILL.md) | [charleswiltgen/axiom](https://github.com/charleswiltgen/axiom) | A skill for optimizing GPU rendering, Metal migration, and shader performance on iOS devices. | 466 | 50 | 2026-02-13 | [graphics](graphics.md), [mobile](mobile.md), [performance](performance.md), [gpu](gpu.md), [metal](metal.md), [shader](shader.md) |
| [axiom-energy](https://github.com/charleswiltgen/axiom/blob/main/.claude-plugin/plugins/axiom/skills/axiom-energy/SKILL.md) | [charleswiltgen/axiom](https://github.com/charleswiltgen/axiom) | Diagnose and fix iOS/iPadOS power consumption issues including battery drain and overheating. | 466 | 37 | 2026-02-13 | [debugging](debugging.md), [performance](performance.md), [battery](battery.md), [cpu](cpu.md), [gpu](gpu.md), [ios](ios.md) |
| [axiom-metal-migration-diag](https://github.com/charleswiltgen/axiom/blob/main/.claude-plugin/plugins/axiom/skills/axiom-metal-migration-diag/SKILL.md) | [charleswiltgen/axiom](https://github.com/charleswiltgen/axiom) | Diagnose and resolve Metal porting issues such as black screens, rendering artifacts, and shader errors. | 466 | 37 | 2026-02-13 | [debugging](debugging.md), [migration](migration.md), [metal](metal.md), [gpu](gpu.md) |
| [particles-gpu](https://github.com/bbeierle12/skill-mcp-claude/blob/main/skills/particles-gpu/SKILL.md) | [bbeierle12/skill-mcp-claude](https://github.com/bbeierle12/skill-mcp-claude) | GPU-based particle systems using instanced rendering and custom shaders for efficient visualization of thousands to millions of particles. | 6 | 32 | 2026-02-05 | [rendering](rendering.md), [visualization](visualization.md), [webgl](webgl.md), [gpu](gpu.md), [threejs](threejs.md) |
| [model-quantization](https://github.com/martinholovsky/claude-skills-generator/blob/main/skills/model-quantization/SKILL.md) | [martinholovsky/claude-skills-generator](https://github.com/martinholovsky/claude-skills-generator) | Optimize and quantize AI models for efficient deployment in resource-constrained environments. | 21 | 26 | 2025-12-06 | [llm-optimization](llm-optimization.md), [optimization](optimization.md), [model-monitoring](model-monitoring.md), [gguf](gguf.md), [gpu](gpu.md) |
| [container-apps-gpu-2025](https://github.com/josiahsiegel/claude-plugin-marketplace/blob/main/plugins/azure-master/skills/container-apps-gpu-2025/SKILL.md) | [josiahsiegel/claude-plugin-marketplace](https://github.com/josiahsiegel/claude-plugin-marketplace) | Azure Container Apps GPU support 2025 with serverless GPU, Dapr integration, and scale-to-zero capabilities. | 13 | 25 | 2026-02-14 | [deployment](deployment.md), [containerization](containerization.md), [azure](azure.md), [gpu](gpu.md), [serverless](serverless.md) |
| [runpod-deployment](https://github.com/scientiacapital/skills/blob/main/active/runpod-deployment-skill/SKILL.md) | [scientiacapital/skills](https://github.com/scientiacapital/skills) | Deploy GPU workloads to RunPod serverless and pods - vLLM endpoints, A100/H100 setup, scale-to-zero, cost optimization. | 1 | 25 | 2026-02-07 | [deployment](deployment.md), [gpu](gpu.md), [runpod](runpod.md), [cost-optimization](cost-optimization.md), [serverless](serverless.md) |
